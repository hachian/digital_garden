- 回帰について説明する。
- 回帰は機械学習のタスクの一つ。
	- 回帰は連続値を予測する。
		- 例：駅からの距離と部屋の広さから家賃を予測する。
	- (クラス)分類は属性を予測する。
		- 例：画像が与えられて、それが猫であることを予測する。
		- 例：文字列が与えられて、次に来る単語を予測する。
	- 周期性があるものは特に時系列解析と呼ぶ。
		- 例：過去のアイスクリーム売り上げデータから今年の売り上げを予測する。
- #機械学習 #AI
- ## 概要
	- [[draws/2023-09-09-19-26-38.excalidraw]]
	- 赤いひし形が与えられたとき、緑の直線を予測する。
		- 緑の直線を$y=ax+b$としたとき、$a$とか$b$を予測する
		- 例：
			- $y$: 家賃
			- $x$: 部屋の広さ
		- 変数が増えるときは$y=a_0+a_1x_1+a_2x_2+\cdots$という感じ
		- 例：
			- $y$: 家賃
			- $x_1$: 部屋の広さ
			- $x_2$: 最寄り駅徒歩時間
			- などなど
		- 赤いひし形一つ一つがデータ、家賃の例だと物件
- ## 切片だけ回帰
	- いきなり$y=ax+b$は複雑なので、$y=b$を予測してみる
		- [[draws/2023-09-09-19-37-40.excalidraw]]
	- 普通に考えると、$y$(=家賃)の値の平均を取ればよさそうだけど、回帰の文脈でやってみる
		- 上記の例だと6件の物件を持ってきて、横軸広さ、縦軸家賃で並べたもの
		- 作戦：$b$を動かして、$b$と$y_i$の差が小さくなるようにする。
			- 今の式：$y=b$
			- 青い線(誤差)：$L=\sum_{i=0}^5(b-y_i)^2=(b-y_0)^2+(b-y_1)^2+\cdots+(b-y_5)^2$
				- 負になるといけないので二乗している。
				- 絶対値でもいいけど、微分しやすい二乗にする。
				- 誤差のイメージ図
				- [[draws/2023-09-09-19-53-00.excalidraw]]
				- $b$を動かすといい感じのところで最小値を取る。
				- $b$がいい感じのところから離れれば離れるほど$L$は大きくなる。
				- $b$が最小値のところは傾きが$0$
					- →微分する。
		- 作戦：$L$を微分して一番いい$b$を見つける。
			- データ何個でもよいように一般化
			- $$L=\sum_{i=0}^n(b-y_i)^2$$
			- $$\frac{dL}{db}=\frac{dL}{db}\sum_{i=0}^n{(b^2-2by_i+y_i^2)}=0$$
			- $$=\sum_{i=0}^n{(2b-2y_i)}=0$$
			- $$b=\frac{1}{n}\sum_{i=0}^n{y_i}$$
	- $b$は$y$の平均でした。
- ## 傾きだけ回帰
	- 切片と同様にやってみる
	- [[draws/2023-09-09-20-09-00.excalidraw]]
	- 式：$y=ax$
	- 誤差：$L=\sum_{i=0}^n(ax_i-y_i)^2$
	- $$\frac{dL}{da}=\frac{dL}{da}\sum_{i=0}^n(ax_i-y_i)^2$$
	- $$=\frac{dL}{da}\sum_{i=0}^n(a^2x_i^2-2ax_iy_i+y_i^2)$$
	- $$=\sum_{i=0}^n(2ax_i^2-2x_iy_i)$$
	-
- ## 線形回帰
- ## 重線形回帰
-